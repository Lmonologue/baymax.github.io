---
layout:         post
title:		"opencv入门例程"
subtitle:	"常用基本函数"
date:           2017-06-16
author:		"HJ."
header-img:	"img/post-bg-2017.jpg"
catalog:	true
tags:
    - opencv
---

# 第一章 数字图像基础

## 1. opencv简介

OpenCV是一个基于BSD许可（开源）发行的跨平台计算机视觉库，可以运行在Linux、Windows、Android和Mac OS操作系统上。它轻量级而且高效，由一系列 C 函数和少量 C++ 类构成，同时提供了Python、Ruby、MATLAB等语言的接口，实现了图像处理和计算机视觉方面的很多通用算法。

Opencv其应用非常广泛，如无人机、无人驾驶等都能看到Opencv的踪迹，很多机器学习也都是基于opencv视觉库。要学好opencv，必看[opencv官网](http://www.opencv.org/)，官网包含Opencv各个版本下载链接、Opencv各平台安装说明以及各API接口函数说明文档，是学习Opencv最好的网站。

学习Opencv不要上来就要弄明白各个细节，入门时，应该多实践，看着教程跑示例，先对Opencv有个基本的认知，再深入去了解背后的算法和c++语言。

## 2. Mat类

在正式介绍之前，先简单一下数字图像的基本概念。在计算机看来一副图像只是一堆亮度各异的点，一副尺寸为M × N的图像可以用一个M × N的矩阵来表示，阵元素的值表示这个位置上像素的亮度，一般来说越大该点亮。一般来说，灰度图用2维矩阵表示，彩色（多通道）图像用3维矩阵（M x N x 3）表示。对于图像显示来说，目前大部分设备都是用无符号8位整数（类型为CV_8U)表示像素亮度。

早期的 OpenCV 中，使用IplImage和CvMat数据结构来表示图像。IplImage和CvMat都是C语言的结构。使用这两个结构的问题是内存需要手动管理，开发者必须清楚的知道何时需要申请内存，释放内存。这个给开发者带来了一定的负担，开发者应该将更多精力用于算法设计，因此在新版本的 OpenCV中引入了Mat类。

Mat本质上是由两个数据部分组成的类：Header和Pointer。Header中主要包含矩阵的大小，存储方式，存储地址等信息，Pointer中存储指向像素值的指针。


- 示例一：创建3行两列5通道矩阵
<pre>
#include < iostream>
#include < opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main()
{
	Mat M(3,2,CV_8UC(5));
	cout<< M << endl;
}
</pre>

- 示例二：创建3行两列3通道矩阵，并赋值
<pre>
#include < iostream>
#include < opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main()
{
	Mat M(3,2,CV_8UC3,Scalar(0,0,255));
	cout<< "M="<< endl<< " "<< M<< endl;
}
</pre>

- 示例三：特殊矩阵

<pre>
#include < iostream>
#include < opencv2/opencv.hpp>

using namespace std;
using namespace cv;

int main()
{
	//0矩阵
	Mat Z=Mat::zeros(2,3,CV_8UC1);
	cout<< Z<< endl;
	
	//1矩阵
	Mat O=Mat::ones(2,3,CV_32F);
	cout<< O<< endl;
	
	//单位矩阵
	Mat E=Mat::eye(2,3,CV_64F);
	cout<< E<< endl;
}
</pre>

## 3. 图像显示

- 示例一：显示图片

<pre>
#include < opencv2/opencv.hpp>
 
using namespace cv; 

int main()
{
	//读取图片，当前目录下，名为1.jpg的图片
	Mat img0=imread("1.jpg");
	//图像拷贝
	Mat img1=img0.clone();
	//图像拷贝
	Mat img2;
	img2=img0;
	//创建同大小，同类型图像，但并不拷贝像素点
	Mat img3;
	img3.create(img0.size(),img0.type());
	
	imshow("img0",img0);
	imshow("img1",img1);
	imshow("img2",img2);
	imshow("img3",img3);

	//这里一定要延时，因为imshow加载图片需要时间，这里0表示无限延时，停在此处
	waitKey(0);
}
</pre>

- 示例二：at()函数遍历像素点，渐变赋值

<pre>
#include < opencv2/opencv.hpp>

using namespace cv;

int main()
{
	//创建图像，大小为600*800
	Mat grayim(600,800,CV_8UC1);
	Mat colorim(600,800,CV_8UC3);
	
	for(int i=0;i< grayim.rows;++i)
		for(int j=0;j< grayim.cols;++j)
			grayim.at < uchar>(i,j)=(i+j)%255;

	for(int i=0;i< colorim.rows;++i)
		for(int j=0;j< colorim.cols;++j)
		{
			//Vec3b表示8U类型的RGB彩色图像向量
			//pixel变量描述RGB颜色
			Vec3b pixel;
			//0通道的B分量
			pixel[0]=i%255;
			//1通道的G分量
			pixel[1]=j%255;
			//2通道的R分量
			pixel[2]=0;
			colorim.at< Vec3b>(i,j)=pixel;
		}
	imshow("grayim",grayim);
	imshow("colorim",colorim);
	waitKey(0);
	return 0;
}
</pre>

- 示例三：MatIterator_容器遍历像素点，随机赋值

<pre>
#include < opencv2/opencv.hpp>

using namespace cv;

int main()
{
	Mat grayim(600,800,CV_8UC1);
	Mat colorim(600,800,CV_8UC3);

	MatIterator_< uchar> grayit,grayend;
	for(grayit=grayim.begin< uchar>(),grayend=grayim.end< uchar>();grayit!=grayend;++grayit)
		*grayit=rand()%255;

	MatIterator_< Vec3b> colorit,colorend;
	for(colorit=colorim.begin< Vec3b>(),colorend=colorim.end< Vec3b>();colorit!=colorend;
	++colorit)
	{
		(*colorit)[0]=rand()%255;
		(*colorit)[1]=rand()%255;
		(*colorit)[2]=rand()%255;
	}

	imshow("grayim",grayim);
	imshow("colorim",colorim);

	waitKey(0);

	return 0;
}
</pre>

- 示例四：打开摄像头

<pre>
#include < opencv2/opencv.hpp>  

using namespace cv;  

int main()  
{  
	//从摄像头读入视频
	VideoCapture capture(0);

	//循环显示每一帧
	while(1)  
	{  
		//定义一个Mat变量，用于存储每一帧的图像
		Mat frame;
		//读取当前帧  
		capture>>frame;
		//显示当前帧  
		imshow("read video",frame);
		//延时30ms  
		waitKey(30);  
	}  
	return 0;     
}  
</pre>

# 第二章 数字图像处理

## 1. 图像滤波

图像滤波，即在尽量保留图像细节特征的条件下对目标图像的噪声进行抑制。消除图像中的噪声成分叫作图像的平滑化或滤波操作。信号或图像的能量大部分集中在幅度谱的低频和中频段是很常见的，而在较高频段，感兴趣的信息经常被噪声淹没。

图像滤波的目的有两个:一是抽出对象的特征作为图像识别的特征模式;另一个是为适应图像处理的要求，消除图像数字化时所混入的噪声。


<pre>
#include < opencv2/opencv.hpp> 

using namespace cv;

//调整各滤波函数参数大小，观察滤波后的效果
int main()
{
	Mat src=imread("lena.jpg");
	Mat dst;
	//高斯滤波，低通就是模糊，高通就是锐化
	GaussianBlur(src,dst,Size(5,5),0,0);
	imwrite("gauss.jpg",dst);
	//中值滤波
	medianBlur(src,dst,3);
	imwrite("med.jpg",dst);
	//均值滤波
	blur(src,dst,Size(3,3),Point(-1,-1));
	imwrite("mean.jpg",dst);
	//双边滤波
	bilateralFilter(src,dst,5,10.0,2.0);
	//将生成的图片写入当前目录
	imwrite("bil.jpg",dst);
	
	waitKey();
	return 0;
}
</pre>

## 2. 图像膨胀与腐蚀

膨胀与腐蚀能实现多种多样的功能，主要如下：

1. 消除噪声
2. 分割(isolate)出独立的图像元素，在图像中连接(join)相邻的元素
3. 寻找图像中的明显的极大值区域或极小值区域
4. 求出图像的梯度

腐蚀和膨胀是对白色部分（高亮部分）而言的，不是黑色部分。膨胀就是图像中的高亮部分进行膨胀，“领域扩张”，效果图拥有比原图更大的高亮区域。腐蚀就是原图中的高亮部分被腐蚀，“领域被蚕食”，效果图拥有比原图更小的高亮区域。

- 示例一：图像膨胀

<pre>
#include < opencv2/opencv.hpp> 

using namespace cv;
 
int main()  
{    
	Mat image = imread("1.jpg");  
	imshow("src", image);
	//获取自定义核  
	Mat element = getStructuringElement(MORPH_RECT, Size(15, 15));  
	Mat out;    
	//进行膨胀操作
	dilate(image,out, element);   
	imshow(" ", out);  
	waitKey(0);  
	return 0;  
} 
</pre>

- 示例二：图像腐蚀

<pre>
#include < opencv2/opencv.hpp> 

using namespace cv;

int main()
{
	Mat srcImage = imread("1.jpg");
	imshow("src", srcImage);
	//获取自定义核 
	Mat element = getStructuringElement(MORPH_RECT, Size(15, 15));
	Mat dstImage;
	//进行腐蚀操作 
	erode(srcImage, dstImage, element);
	imshow(" ", dstImage);
	waitKey(0); 

	return 0;
}
</pre>

## 3. 边缘检测

缘检测一般步骤:

1. 滤波：边缘检测的算法主要是基于图像强度的一阶和二阶导数，但导数通常对噪声很敏感，因此必须采用滤波器来改善与噪声有关的边缘检测器的性能。
2. 增强：增强边缘的基础是确定图像各点邻域强度的变化值。增强算法可以将图像灰度点邻域强度值有显著变化的点凸显出来。
3. 检测：经过增强的图像，往往邻域中有很多点的梯度值比较大，而在特定的应用中，这些点并不是我们要找的边缘点，所以应该采用某种方法来对这些点进行取舍。实际工程中，常用的方法是通过阈值化方法来检测。

边缘检测有canny算子、laplace算子、sobel算子以及scharr算子算法

- 示例一：canny算子

<pre>
#include < opencv2/opencv.hpp> 

using namespace cv;

int main()
{  
    Mat src=imread("1.jpg");  
    Mat src1=src.clone();  
  
    imshow("src",src);   
   
    Canny(src,src,150,100,3);  
    imshow("result1", src);   
  
    Mat dst,edge,gray;  
  
    //创建与src同类型和大小的矩阵(dst)  
    dst.create(src1.size(),src1.type());  
    //将原图像转换为灰度图像  
    cvtColor(src1,gray,CV_BGR2GRAY );  
    //先用使用3x3内核来降噪  
    blur(gray,edge,Size(3,3));  
    //运行Canny算子
    Canny(edge,edge,3,9,3);  
    //将dst内的所有元素设置为0   
    dst=Scalar::all(0);  
    //使用Canny算子输出的边缘图edge作为掩码，将原图src拷到目标图dst中
    //copyTo将src1中edge矩阵对应的非零部分复制到dst中  
    src1.copyTo(dst,edge);  
   
    imshow("result2",dst);
   
    waitKey(0);   
    return 0;
}
</pre>

- 示例二：sobel算子

`Sobel()`算子是一个主要用作边缘检测的离散微分算子，它结合了高斯平滑和微分求导，用来计算图像灰度函数的近似梯度。在图像的任何一点使用此算子，将会产生对应的梯度矢量或是其法矢量。

<pre>
#include < opencv2/opencv.hpp>  

using namespace cv;

int main()  
{  
    //创建 grad_x 和 grad_y 矩阵  
    Mat grad_x, grad_y;  
    Mat abs_grad_x, abs_grad_y,dst;  
     
    Mat src = imread("1.jpg");
    imshow("src",src);   
  
    //求 X方向梯度  
    Sobel(src,rad_x,CV_16S,1,0,3,1,1,BORDER_DEFAULT);  
    convertScaleAbs(grad_x, abs_grad_x);  
    imshow("X方向Sobel",abs_grad_x);   
  
    //求Y方向梯度  
    Sobel(src,grad_y,CV_16S,0,1,3,1,1,BORDER_DEFAULT );  
    convertScaleAbs(grad_y,abs_grad_y);  
    imshow("Y方向Sobel",abs_grad_y);   
  
    //合并梯度(近似)  
    addWeighted(abs_grad_x,0.5,abs_grad_y,0.5,0,dst);  
    imshow("整体方向Sobel",dst);   
  
    waitKey(0);   
    return 0;   
} 
</pre>

- 示例三：laplace算子

`laplacian()`函数可以计算出图像经过拉普拉斯变换后的结果

<pre>
#include < opencv2/opencv.hpp>  

using namespace cv;  
  
int main()  
{  
    Mat src,src_gray,dst, abs_dst;    
    src = imread("1.jpg");  
    imshow("src", src);   
  
    //使用高斯滤波消除噪声  
    GaussianBlur(src,src,Size(3,3),0,0,BORDER_DEFAULT);  
    //转换为灰度图  
    cvtColor(src,src_gray,CV_RGB2GRAY);  
    //使用Laplace函数  
    Laplacian(src_gray,dst,CV_16S,3,1,0,BORDER_DEFAULT);  
    //计算绝对值，并将结果转换成8位  
    convertScaleAbs(dst,abs_dst );  
  
    imshow("图像Laplace变换",abs_dst);  
    waitKey(0);   
  
    return 0;   
}  
</pre>


- 示例四：scharr滤波器

使用`Scharr()`滤波器运算符计算x或y方向的图像差分，它的参数变量和Sobel基本上是一样的，除了没有ksize核的大小。

<pre>
#include < opencv2/opencv.hpp>  

using namespace cv;  

int main( )  
{  
    //创建grad_x和grad_y矩阵  
    Mat grad_x, grad_y;  
    Mat abs_grad_x,abs_grad_y,dst;  
  
    Mat src = imread("1.jpg"); 
    imshow("src", src);   
  
    //求X方向梯度  
    Scharr(src,grad_x, CV_16S,1,0,1,0,BORDER_DEFAULT);  
    convertScaleAbs(grad_x, abs_grad_x );  
    imshow("X方向Scharr", abs_grad_x);   
    //求Y方向梯度  
    Scharr(src,grad_y,CV_16S,0,1,1,0,BORDER_DEFAULT);  
    convertScaleAbs(grad_y,abs_grad_y);  
    imshow("Y方向Scharr",abs_grad_y);   
    //合并梯度(近似)  
    addWeighted(abs_grad_x,0.5,abs_grad_y,0.5,0,dst);  
  

    imshow("合并梯度后Scharr",dst);   
  
    waitKey(0);   
    return 0;   
}  
</pre>

##4. 图像融合

`addWeighted()`这个函数的作用是，计算两个数组（图像阵列）的加权和。

`void addWeighted(InputArray src1,double alpha, InputArray src2, double beta, double gamma, OutputArray dst, int dtype=-1);`

- src1：表示需要加权的第一个数组。
- alpha：表示第一个数组的权重
- src2：表示第二个数组，它需要和第一个数组拥有相同的尺寸和通道数。
- beta：表示第二个数组的权重值。
- dst：输出的数组，它和输入的两个数组拥有相同的尺寸和通道数。
- gamma：一个加到权重总和上的标量值。
- dtype：输出阵列的可选深度，有默认值-1。

<pre>
#include < opencv2/opencv.hpp>

using namespace cv;

int main()
{
	Mat image1=imread("1.jpg",1);
	Mat image2=imread("2.jpg",1);
	Mat image;
	addWeighted(image1,0.8,image2,0.2,0.0,image);

	imshow("1",image1);
	imshow("2",image2);
	imshow("new",image);

	waitKey(0);
	return 0;
} 
</pre>

## 5. 分离颜色通道

- split()函数将一个多通道数组分离成几个单通道数组。
- merge()函数的功能是split函数的逆向操作，将多个数组组合合并成一个多通道的数组。

<pre>
#include < opencv2/opencv.hpp>

using namespace cv;

int main()
{
	Mat srcImage;
	Mat grayImage;
	Mat imageBlueChannel;
	vector< Mat>channels;
	
	srcImage=imread("1.jpg");
	imshow("src",srcImage);
	//读取灰度图像
	grayImage=imread("1.jpg",0);
	//分离颜色通道
	split(srcImage,channels);
	//选取蓝色通道
	imageBlueChannel=channels.at(0);
	//融合蓝色通道与灰度图像
	addWeighted(imageBlueChannel,1.0,grayImage,0.5,0.0,imageBlueChannel);
	//合并颜色通道，相当于对原图像蓝色通道加强
	merge(channels,imageBlueChannel);

	imshow("blue",imageBlueChannel);

	waitKey(0);
	return 0;
}
}
</pre>

## 6. RGB与HSV空间转换

<pre>
#include < opencv2/opencv.hpp>

using namespace cv;

int main()
{
	Mat srcImage=imread("1.jpg");
	cvtColor(srcImage,srcImage,COLOR_BGR2HSV);
	imshow(" ",srcImage);
	waitKey();
}
</pre>

# 第三章 图像缩放

## 1. 图像旋转

`getRotationMatrix2D()`函数主要用于获得图像绕着某一点的旋转矩阵。 

`getRotationMatrix2D(Point2f center,double angle,double scale)`

- Point2f center：表示旋转的中心点。
- double angle：表示旋转的角度。
- double scale：图像缩放因子。

<pre>
#include <opencv2/opencv.hpp>

using namespace cv;

void img_rotate(Mat src_img,Mat* rotate_img,int angle)
{
	Point2f center=Point2f(src_img.cols/2,src_img.rows/2);
	Mat rotateMat=getRotationMatrix2D(center,angle,1);
	warpAffine(src_img,*rotate_img,rotateMat,src_img.size()); 
}

int main()
{
	Mat srcImage,dstImage;
	srcImage=imread("1.jpg");
	img_rotate(srcImage,&dstImage,180);
	imshow(" ",dstImage);
	waitKey();
}
</pre>

## 2. 图像缩放

- 示例一：resize函数

`resize()`函数将源图像精确地转换为指定尺寸的目标图像。

`void resize(InputArray src,OutputArray dst, Size dsize, double fx=0, double fy=0, int interpolation=INTER_LINEAR )`

- src：输入图像。
- dst：输出图像。
- dsize：输出图像的大小。
- fx：沿水平轴的缩放系数。
- fy：沿垂直轴的缩放系数。
- interpolation：用于指定插值方式，默认为INTER_LINEAR（线性插值）。

<pre>
#include <opencv2/opencv.hpp>

using namespace cv;

int main()
{
	Mat srcImage = imread("1.jpg");
	Mat tmpImage,dstImage1,dstImage2;
	tmpImage=srcImage;

	//进行尺寸调整操作
	resize(tmpImage,dstImage1,Size( tmpImage.cols/2, tmpImage.rows/2 ),(0,0),(0,0),3);
	resize(tmpImage,dstImage2,Size( tmpImage.cols*2, tmpImage.rows*2 ),(0,0),(0,0),3);

	imshow("resize1", dstImage1);  
	imshow("resize2", dstImage2);  

	waitKey(0);  
	return 0;  
}
</pre>

- 示例二：pyrUp函数

`pyrUp()`函数的作用是向上采样并模糊一张图像，说白了就是放大一张图片。

<pre>
#include < opencv2/opencv.hpp>  
 
using namespace cv;  

int main()  
{     
    Mat srcImage = imread("1.jpg");
    Mat tmpImage,dstImage;
    tmpImage=srcImage;
    imshow("srcImage", srcImage);  
  
    pyrUp( tmpImage, dstImage, Size( tmpImage.cols*2, tmpImage.rows*2 ) );  
     
    imshow("dstImage", dstImage);    
    waitKey(0);    
  
    return 0;    
}
</pre>

- 示例三：pyrDown函数

`pyrDown()`函数的作用是向下采样并模糊一张图片，说白了就是缩小一张图片。

<pre> 
#include < opencv2/opencv.hpp>   
 
using namespace cv;  
    
int main()  
{    
    Mat srcImage = imread("1.jpg");
    Mat tmpImage,dstImage;  
    tmpImage=srcImage;
  
    imshow("srcImage", srcImage);      
    pyrDown( tmpImage, dstImage, Size( tmpImage.cols/2, tmpImage.rows/2 ) );    
    imshow("dstImage", dstImage);    
  
    waitKey(0);    
    return 0;    
}  

</pre>

# 第四章 图像分割

## 1. 图像分割

<pre>
#include < opencv2/opencv.hpp>  
 
using namespace cv;  
  
//剪切图片为m * n 块  
void Cut_img(Mat src_img,int m,int n,Vector< Mat> ceil_img)
{  
    int t = m * n;  
    int height = src_img.rows;  
    int width  = src_img.cols;  
  
    int ceil_height = height/m;  
    int ceil_width  = width/n;   
  
    Mat roi_img,tmp_img;  
  
    Point p1,p2;  
    for(int i = 0;i< m;i++)  
        for(int j = 0;j< n;j++)
        {   
            Rect rect(i+j*ceil_width,j+i*ceil_height,ceil_width,ceil_height);  
            src_img(rect).copyTo(roi_img);  
            ceil_img.push_back(roi_img);  
            imshow("roi_img",roi_img); 
			//关闭当前显示中的图像，才可以显示其他图像   
            waitKey(0);   
        }     
}  
 
  
int main()  
{  
    Mat img = imread("lena.jpg",1);  
    imshow("src img",img);  
    int m = 3;  
    int n = 3;
  
    Vector< Mat> ceil_img = m*n;  
  
    Cut_img(img,m,n,ceil_img);  

    waitKey();  
    return 0;  
} 
</pre>

## 2. 获取感兴趣区

<pre>
#include < opencv2/opencv.hpp> 

using namespace cv;
using namespace std;

void getROI(Mat src_image,Mat* dst_roi,Rect rect);//获取兴趣区
void setRect(Rect* rect,int x,int y,int width,int height);//设置矩形区

int main()
{
	Mat image=imread("1.jpg");
	Mat roi;
	Rect rect;

	imshow("Origin",image);
	cout<< "width:"<< image.cols<< " "<< "height:"<< image.rows<< endl;
	
	setRect(&rect,320,240,150,150);
	getROI(image,&roi,rect);

	imshow("ROI",roi);
	waitKey(0);
	return 0;
}

void setRect(Rect* rect,int x,int y,int width,int height)
{
	(*rect).x=x;
	(*rect).y=y;
	(*rect).width=width;
	(*rect).height=height;
}

void getROI(Mat src_image,Mat* dst_roi,Rect rect)
{
	Mat img=src_image.clone();

	int cols=img.cols,rows=img.rows;
	if(cols - 1 - rect.x< rect.width||rows - 1 - rect.y< rect.height)
		cout<< "over area!"<< endl;
	*dst_roi=img(Rect(rect.x,rect.y,rect.width,rect.height));
}

</pre>

## 3. 图像拼接

<pre>
#include < opencv2/opencv.hpp>  
  
using namespace cv;

int main()
{  
	Mat combine1,combine2,combine;
	Mat img1 = imread("1.jpg",1);
	Mat img2 = imread("2.jpg",1); 
	Mat img3 = imread("3.jpg",1); 
	Mat img4 = imread("4.jpg",1); 
  
	hconcat(img1,img2,combine1);  
	hconcat(img3,img4,combine2);  
	vconcat(combine1,combine2,combine);

	imshow("roi_img",roi_img);    
	waitKey(0);
}   
</pre>

# 第五章 图像识别

## 1. 直线识别

<pre>
#include < opencv2/opencv.hpp>  
 
using namespace cv;

int main()  
{  
    Mat srcImage = imread("1.jpg");
    Mat midImage,dstImage;  
  
    Canny(srcImage, midImage, 50, 200, 3);
    cvtColor(midImage,dstImage, CV_GRAY2BGR);
    
    vector< Vec4i> lines; 
    HoughLinesP(midImage, lines, 1, CV_PI/180, 80, 50, 10 );  
  
    //依次在图中绘制出每条线段  
    for(size_t i = 0; i < lines.size(); i++)  
    { 
        Vec4i l = lines[i];  
        line(dstImage,Point(l[0], l[1]),Point(l[2], l[3]),Scalar(186,88,255),1,CV_AA);  
    }   
    imshow(" ", dstImage);    
    waitKey(0);    
  
    return 0;    
}
</pre>

## 2. 矩形识别

<pre>
#include < opencv2/opencv.hpp>  

using namespace cv;

int main()
{
	Mat src_image=imread("1.jpg");
	Mat gray_image;
	cvtColor(src_image,gray_image,CV_BGR2GRAY);
	imshow("src",src_image);

	Mat binary_image;

	//局部自适应二值化函数
	adaptiveThreshold(gray_image,binary_image,255,CV_ADAPTIVE_THRESH_MEAN_C,CV_THRESH_BINARY_INV,25,10);  

	imshow("binary",binary_image);

	Mat de_noise=binary_image.clone();
	medianBlur(binary_image,de_noise,5); //中值滤波 

	Mat dilate_image;//膨胀
	Mat element=getStructuringElement(MORPH_RECT,Size(20,20));
	dilate(de_noise,dilate_image,element);
	imshow("dilate",dilate_image);

	//外部加框,检测连通域,每一个连通域以一系列的点表示,FindContours方法只能得到第一个域
	vector< vector< Point> > contours;
	vector< Vec4i> hierarchy;
	
	//CV_RETR_EXTERNAL只检测外部轮廓，可根据自身需求进行调整  
	findContours(dilate_image,contours,hierarchy,CV_RETR_EXTERNAL,CV_CHAIN_APPROX_NONE);

	Mat contours_image(dilate_image.rows,dilate_image.cols,CV_8U,Scalar(255));
	int index=0;
	for(;index>=0;index=hierarchy[index][0])
	{
		Scalar color(rand()&255,rand()&255,rand()&255);
		drawContours(contours_image,contours,index,Scalar(0),1,8,hierarchy);//描绘字符的外轮廓
		Rect rect=boundingRect(contours[index]);//检测外轮廓  
		rectangle(contours_image,rect,Scalar(0,0,255),3);//对外轮廓加矩形框 
	}
	imshow("zt",contours_image);

	waitKey(0);
}
</pre>

## 3. 圆形识别

<pre>
#include < opencv2/opencv.hpp>  

using namespace cv;

int main()  
{      
    Mat srcImage = imread("1.jpg");  
    Mat midImage,dstImage;
    
    cvtColor(srcImage,midImage, CV_BGR2GRAY);//转化边缘检测后的图为灰度图  
    GaussianBlur( midImage, midImage, Size(9, 9), 2, 2 );  
   
    vector<Vec3f> circles;  
    HoughCircles( midImage, circles, CV_HOUGH_GRADIENT,1.5, 10, 200, 100, 0, 0 );  
  
    //依次在图中绘制出圆  
    for( size_t i = 0; i < circles.size(); i++ )  
    {  
        Point center(cvRound(circles[i][0]), cvRound(circles[i][1]));  
        int radius = cvRound(circles[i][2]);  
        //绘制圆心  
        circle( srcImage, center, 3, Scalar(0,255,0), -1, 8, 0 );  
        //绘制圆轮廓  
        circle( srcImage, center, radius, Scalar(155,50,255), 3, 8, 0 );  
    }  
   
    imshow(" ", srcImage);    
    waitKey(0);    
    return 0;    
}
 
</pre>

## 4. 彩色目标跟踪

CamShift 算法即连续自适应的MeanShift算法。其基本思想是对视频序列的所有图像帧都作MeanShift运算，并将上一帧的结果（即搜索窗口的中心位置和窗口大小）作为下一帧MeanShift算法的搜索窗口的初始值，如此迭代下去。简单点说，meanShift是针对单张图片寻找最优迭代结果，而camShift则是针对视频序列来处理，并对该序列中的每一帧图片都调用meanShift来寻找最优迭代结果。正是由于camShift针对一个视频序列进行处理，从而保证其可以不断调整窗口的大小，如此一来，当目标的大小发生变化的时候，该算法就可以自适应地调整目标区域继续跟踪。

该算法对于简单背景下的单目标跟踪效果较好，但如果被跟踪目标与背景颜色或周围其它目标颜色比较接近，则跟踪效果较差。另外，由于采用颜色特征，所以它对被跟踪目标的形状变化有一定的抵抗能力。 　

处理步骤：

- 计算色彩投影图（反向投影）：

	- 为了减少光照变化对目标跟踪的影响，首先将图像从RGB颜色空间转换到HSV颜色空间；
	- 对H分量进行直方图统计，直方图代表了不同H分量取值出现的概率，或者说可以据此查找出H分量的大小为x时的概率或像素个数，即，得到颜色概率查找表；
	- 将图像中每个像素的值用其颜色出现的概率进行替换，由此得到颜色概率分布图；

<pre>
#include <opencv2/opencv.hpp>  

using namespace cv;
using namespace std;

Mat image;
bool backprojMode = false;//是否要进入反向投影模式，true表示准备进入反向投影模式 
bool selectObject = false;//是否在选要跟踪的初始目标，true表示正在用鼠标选择
int trackObject = 0;//代表跟踪目标数目
bool showHist = true;//是否显示直方图  
Point origin;//用于保存鼠标选择第一次单击时点的位置  
Rect selection;//用于保存鼠标选择的矩形框
int vmin = 10, vmax = 256, smin = 30;

static void onMouse( int event, int x, int y, int, void* )
{
	if( selectObject )//只有当鼠标左键按下去时才有效
	{
		selection.x = MIN(x, origin.x);//矩形左上角顶点坐标
		selection.y = MIN(y, origin.y);
		selection.width = std::abs(x - origin.x);
		selection.height = std::abs(y - origin.y);

		//两矩形的交集，用于确保所选的矩形区域在图片范围内
		selection &= Rect(0, 0, image.cols, image.rows);
	}

	switch( event )
	{
	case CV_EVENT_LBUTTONDOWN:
		origin = Point(x,y);
		selection = Rect(x,y,0,0);//鼠标刚按下去时，初始化了一个矩形区域
		selectObject = true;
		break;
	case CV_EVENT_LBUTTONUP://松开鼠标
		selectObject = false;
		if( selection.width > 0 && selection.height > 0 )
			trackObject = -1;
		break;
	}
}

const char* keys =
{
	"{1|  | 0 | camera number}"
};

int main( int argc, const char** argv )
{
	VideoCapture cap;//定义一个摄像头捕捉的类对象
	Rect trackWindow;
	int hsize = 16;
	float hranges[] = {0,180};//hranges在后面的计算直方图函数中要用到
	const float* phranges = hranges;  

	cap.open(0);

	if( !cap.isOpened() )
	{
		cout << "open camera error!\n";
	}

	namedWindow( "Histogram", 0 );//直方图
	namedWindow( "CamShift Demo", 0 );
	setMouseCallback( "CamShift Demo", onMouse, 0 );//消息响应机制  
	//创建滑动条，0代表没有调用滑动拖动的响应函数
	createTrackbar( "Vmin", "CamShift Demo", &vmin, 256, 0 );
	createTrackbar( "Vmax", "CamShift Demo", &vmax, 256, 0 );
	createTrackbar( "Smin", "CamShift Demo", &smin, 256, 0 );

	Mat frame, hsv, hue, mask, hist, histimg = Mat::zeros(200, 320, CV_8UC3), backproj;
	bool paused = false;

	for(;;)
	{
		if( !paused )//没有暂停  
		{
			cap >> frame;
			if( frame.empty() )
				break;
		}

		frame.copyTo(image);

		if( !paused )//没有暂停  
		{
			cvtColor(image, hsv, COLOR_BGR2HSV);

			if( trackObject )//trackObject初始化为0,或者按完键盘的'c'键后也为0，当鼠标单击松开后为-1  
			{
				int _vmin = vmin, _vmax = vmax;

				//将rgb摄像头帧转化成hsv空间
				inRange(hsv, Scalar(0, smin, MIN(_vmin,_vmax)),
							 Scalar(180, 256, MAX(_vmin, _vmax)), 
							 mask);
				int ch[] = {0, 0};
				//hue初始化为与hsv大小深度一样的矩阵，色调的度量是用角度表示的，红绿蓝之间相差120度，反色相差180度 
				hue.create(hsv.size(), hsv.depth()); 
				mixChannels(&hsv, 1, &hue, 1, ch, 1);//将hsv第一个通道(也就是色调)的数复制到hue中，0索引数组  

				if( trackObject < 0 )//鼠标选择区域松开后，该函数内部又将其赋值1 
				{
					//此处的构造函数roi用的是Mat hue的矩阵头，且roi的数据指针指向hue
					//即共用相同的数据，select为其感兴趣的区域 
					Mat roi(hue, selection), maskroi(mask, selection);//mask保存的hsv的最小值
					//将roi的0通道计算直方图并通过mask放入hist中，hsize为每一维直方图的大小  
					calcHist(&roi, 1, 0, maskroi, hist, 1, &hsize, &phranges);
					//将hist矩阵进行数组范围归一化，都归一化到0~255  
					normalize(hist, hist, 0, 255, CV_MINMAX);

					trackWindow = selection;

					//只要鼠标选完区域松开后，且没有按键盘清0键'c'，则trackObject一直保持为1
					//因此该if函数只能执行一次，除非重新选择跟踪区域
					trackObject = 1;

					histimg = Scalar::all(0);//与按下'c'键是一样的，这里的all(0)表示的是标量全部清0  
					
					//histing是一个200*300的矩阵，hsize应该是每一个bin的宽度，也就是histing矩阵能分出几个bin出来  
					int binW = histimg.cols / hsize;
					Mat buf(1, hsize, CV_8UC3);//定义一个缓冲单bin矩阵

					//saturate_case函数为从一个初始类型准确变换到另一个初始类型  
					for( int i = 0; i < hsize; i++ )
						//Vec3b为3个char值的向量  
						buf.at<Vec3b>(i) = Vec3b(saturate_cast<uchar>(i*180./hsize), 255, 255);
					cvtColor(buf, buf, CV_HSV2BGR);//将hsv又转换成bgr  

					for( int i = 0; i < hsize; i++ )
					{
						//at函数为返回一个指定数组元素的参考值  
						int val = saturate_cast<int>(hist.at<float>(i)*histimg.rows/255);
						//在一幅输入图像上画一个简单抽的矩形，指定左上角和右下角，并定义颜色，大小，线型等  
						rectangle( histimg, Point(i*binW,histimg.rows),
									Point((i+1)*binW,histimg.rows - val),
									Scalar(buf.at<Vec3b>(i)), -1, 8 );
					}
				}

				//计算直方图的反向投影，计算hue图像0通道直方图hist的反向投影，并让入backproj中  
				calcBackProject(&hue, 1, 0, hist, backproj, &phranges);
				backproj &= mask;

				//trackWindow为鼠标选择的区域，TermCriteria为确定迭代终止的准则  
				RotatedRect trackBox = CamShift(backproj, trackWindow,
					TermCriteria( CV_TERMCRIT_EPS | CV_TERMCRIT_ITER, 10, 1 ));
				if( trackWindow.area() <= 1 )
				{
					int cols = backproj.cols, rows = backproj.rows, r = (MIN(cols, rows) + 5)/6;
					trackWindow = Rect(trackWindow.x - r, trackWindow.y - r,
									   trackWindow.x + r, trackWindow.y + r) &
								  Rect(0, 0, cols, rows);
				}

				if( backprojMode )
					cvtColor( backproj, image, COLOR_GRAY2BGR );
				//跟踪的时候以椭圆为代表目
				ellipse( image, trackBox, Scalar(0,0,255), 3, CV_AA );
			}
		}

		//后面的代码是不管pause为真还是为假都要执行的  
		else if( trackObject < 0 )
			paused = false;

		if( selectObject && selection.width > 0 && selection.height > 0 )
		{
			Mat roi(image, selection);
			bitwise_not(roi, roi);
		}

		imshow( "CamShift Demo", image );
		imshow( "Histogram", histimg );

		char c = (char)waitKey(10);
		if( c == 27 )
			break;
		switch(c)
		{
		case 'b':
			backprojMode = !backprojMode;
			break;
		case 'c':
			trackObject = 0;
			histimg = Scalar::all(0);
			break;
		case 'h':
			showHist = !showHist;
			if( !showHist )
				destroyWindow( "Histogram" );
			else
				namedWindow( "Histogram", 1 );
			break;
		case 'p':
			paused = !paused;
			break;
		default:
			;
		}
	}

	return 0;
}

</pre>

